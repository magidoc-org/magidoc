# Deployment - Google Indexing

If you wish your website to be indexed and searchable on Google, you will need to provide a custom [robots.txt](https://developers.google.com/search/docs/advanced/robots/intro), which allows your website to be crawled by search engines.

## Magidoc configuration

You need to use `staticAssets` to provide a `robots.txt`.

```javascript
import path from 'path'

export default {
  website: {
    // ...
    staticAssets: path.join(__dirname, 'assets'),
    // ...
  },
}
```

## Robots file

Once this is done, you need to create a `robots.txt` file inside the `assets` directory.

```
assets
└── robots.txt
magidoc.mjs
```

The minimal content you can put in there is the following, which allows Google to crawl everything on your website.

```
User-agent: *
Disallow:
```
